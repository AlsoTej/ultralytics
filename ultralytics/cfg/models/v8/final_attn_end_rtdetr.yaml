# nc: 2 # number of classes
# scales:
#   s: [1.0, 1.0, 1536]

# backbone:
#   - [-1, 1, nn.Identity, []] # 0

#   # CNN (ConvNeXt Tiny)
#   - [0, 1, TorchVision, [768, "convnext_tiny", "DEFAULT", True, 2, True]]  # 1
#   - [-1, 1, Index, [192, 4]]  # extracts 4th output (1, 192, 80, 80) - 2
#   - [1, 1, Index, [384, 6]]  # extracts 6th output (1, 384, 40, 40) - 3
#   - [1, 1, Index, [768, 8]]  # extracts 8th output (1, 768, 20, 20) - 4
#   - [-1, 1, SPPF, [768, 3]]  # 5: Add SPPF for ConvNeXt (768 channels, kernel size 5)

#   # Swin Transformer
#   - [0, 1, TorchVision, [768, swin_v2_t, DEFAULT, True, 4, True]] # 6
#   - [-1, 1, Index, [192, 4]] # 7
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 8 (multiscale 1)
#   - [6, 1, Index, [384, 6]] # 9
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 10 (multiscale 2)
#   - [6, 1, Index, [768, 9]] # 11
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 12 (multiscale 3)
#   - [-1, 1, SPPF, [768, 3]]  # 13: Add SPPF for Swin Transformer (768 channels, kernel size 5)

#   # Concat features along channel dimension
#   - [[2, 8], 1, Concat, [1]] # 14 concat scale 1 (192 + 192 = 384 channels)
#   - [[3, 10], 1, Concat, [1]] # 15 concat scale 2 (384 + 384 = 768 channels)
#   - [[5, 13], 1, Concat, [1]] # 16 concat scale 3 (768 + 768 = 1536 channels)

# head:
#   # Top-Down Pathway
#   - [16, 1, nn.Upsample, [None, 2, "nearest"]] # 17 upsample concat3 output to match H and W with concat2
#   - [[-1, 15], 1, BiFPN_Concat2, [1]] # 18 concat concat3 + concat2 (1536 + 768 = 2304 channels)
#   - [-1, 1, C3k2, [448, False]] # 19 reduce channels to 448 (was 512, ~23% reduction)

#   - [19, 1, nn.Upsample, [None, 2, "nearest"]] # 20 upsample to match H and W with concat1
#   - [[-1, 14], 1, BiFPN_Concat2, [1]] # 21 concat with concat1 (448 + 384 = 832 channels)
#   - [-1, 1, C3k2, [224, False]] # 22 reduce channels to 224 (was 256, ~23% reduction) (P3 before EMA)

#   # Bottom-Up Pathway
#   - [22, 1, DWConv, [224, 3, 2]]    # 23: Downsample (input channels adjusted to 224)
#   - [[-1, 19], 1, BiFPN_Concat2, [1]]    # 24: BiFPN Concatenate (224 + 448 = 672 channels)
#   - [-1, 1, C3k2, [448, True]]     # 25: C2f (reduce to 448 channels, was 512, ~23% reduction) (P4 before EMA)

#   - [25, 1, DWConv, [448, 3, 2]]    # 26: Downsample (input channels adjusted to 448)
#   - [[-1, 16], 1, BiFPN_Concat2, [1]]    # 27: Concatenate with concat3 (448 + 1536 = 1984 channels)
#   - [-1, 1, C3k2, [896, True]]    # 28: C2f (reduce to 896 channels, was 1024, ~23% reduction) (P5 before EMA)

#   # Apply EMA to P3, P4, P5 before detection
#   - [22, 1, EMA, [224]]  # 29: EMA for P3 (224 channels, was 256)
#   - [25, 1, EMA, [448]]  # 30: EMA for P4 (448 channels, was 512)
#   - [28, 1, EMA, [896]]  # 31: EMA for P5 (896 channels, was 1024)

#   # Detection
#   - [[29, 30, 31], 1, RTDETRDecoder, [nc]]  # 32: Detect(P3, P4, P5)


nc: 2 # number of classes
scales:
  s: [1.0, 1.0, 1536]

backbone:
  - [-1, 1, nn.Identity, []] # 0

  # CNN (ConvNeXt Tiny)
  - [0, 1, TorchVision, [768, "convnext_tiny", "DEFAULT", True, 2, True]]  # 1
  - [-1, 1, Index, [192, 4]]  # extracts 4th output (1, 192, 80, 80) - 2
  - [1, 1, Index, [384, 6]]  # extracts 6th output (1, 384, 40, 40) - 3
  - [1, 1, Index, [768, 8]]  # extracts 8th output (1, 768, 20, 20) - 4
  - [-1, 1, SPPF, [768, 3]]  # 5: Add SPPF for ConvNeXt (768 channels, kernel size 5)
  - [-1, 1, EMA, [768]] #6

  # Swin Transformer
  - [0, 1, TorchVision, [768, swin_v2_t, DEFAULT, True, 4, True]] # 7
  - [-1, 1, Index, [192, 4]] # 8
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 9 (multiscale 1)
  - [7, 1, Index, [384, 6]] # 10
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 11 (multiscale 2)
  - [7, 1, Index, [768, 9]] # 12
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 13 (multiscale 3)
  - [-1, 1, SPPF, [768, 3]]  # 14: Add SPPF for Swin Transformer (768 channels, kernel size 5)
  - [-1, 1, EMA, [768]] # 15


  - [[6, 15], 1, Concat, [1]] # 16 concat scale 3 (768 + 768 = 1536 channels)


head:
  # Top-Down Pathway
  - [16, 1, nn.Upsample, [None, 2, "nearest"]] # 17 upsample EMA3 output to match H and W with EMA2
  - [[-1, 3, 11], 1, BiFPN_Concat3, [1]] # 18 concat EMA3 + EMA2 (1536 + 768 = 2304 channels)
  - [-1, 1, C3k2, [512, False]] # 19 reduce channels to 512

  - [19, 1, nn.Upsample, [None, 2, "nearest"]] # 20 upsample to match H and W with EMA1
  - [[-1, 2, 9], 1, BiFPN_Concat3, [1]] # 21 concat with EMA1 (512 + 384 = 896 channels)
  - [-1, 1, C3k2, [256, False]] # 22 reduce channels to 256

  # Bottom-Up Pathway
  - [22, 1, DWConv, [256, 3, 2]]    # 23: Downsample
  - [[-1, 19], 1, BiFPN_Concat2, [1]]    # 24: BiFPN Concatenate (256 + 512 = 768 channels)
  - [-1, 1, C3k2, [512, True]]     # 25: C2f (reduce to 512 channels)

  - [28, 1, DWConv, [512, 3, 2]]    # 26: Downsample
  - [[-1, 16], 1, BiFPN_Concat2, [1]]    # 27: Concatenate with EMA3 (512 + 1536 = 2048 channels)
  - [-1, 1, C3k2, [1024, True]]    # 28: C2f (reduce to 1024 channels)

  # Detection
  - [[22, 25, 28], 1, RTDETRDecoder, [nc]]  # 29: Detect(P3, P4, P5)

