nc: 2 # number of classes
scales:
  s: [1.0, 1.0, 1536]

backbone:
  - [-1, 1, nn.Identity, []] # 0

  # CNN (ConvNeXt Tiny)
  - [0, 1, TorchVision, [768, "convnext_tiny", "DEFAULT", True, 2, True, False]]  # 1
  - [-1, 1, Index, [192, 4]]  # extracts 4th output (1, 192, 80, 80) - 2
  - [1, 1, Index, [384, 6]]  # extracts 6th output (1, 384, 40, 40) - 3
  - [1, 1, Index, [768, 8]]  # extracts 8th output (1, 768, 20, 20) - 4
  - [-1, 1, SPPF, [768, 3]]  # 5: Add SPPF for ConvNeXt (768 channels, kernel size 5)

  # Swin Transformer
  - [0, 1, TorchVision, [768, swin_v2_t, DEFAULT, True, 4, True, True]] # 6
  - [-1, 1, Index, [192, 4]] # 7
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 8 (multiscale 1)
  - [6, 1, Index, [384, 6]] # 9
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 10 (multiscale 2)
  - [6, 1, Index, [768, 9]] # 11
  - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 12 (multiscale 3)
  - [-1, 1, SPPF, [768, 3]]  # 13: Add SPPF for Swin Transformer (768 channels, kernel size 5)

  # Concat features along channel dimension
  - [[2, 8], 1, Concat, [1]] # 14 concat scale 1 (192 + 192 = 384 channels)
  - [-1, 1, EMA, [384]]      # 15 EMA for scale 1

  - [[3, 10], 1, Concat, [1]] # 16 concat scale 2 (384 + 384 = 768 channels)
  - [-1, 1, EMA, [768]]      # 17 EMA for scale 2

  - [[5, 13], 1, Concat, [1]] # 18 concat scale 3 (768 + 768 = 1536 channels)
  - [-1, 1, EMA, [1536]]      # 19 EMA for scale 3

head:
  # Top-Down Pathway
  - [19, 1, nn.Upsample, [None, 2, "nearest"]] # 20 upsample EMA3 output to match H and W with EMA2
  - [[-1, 17], 1, BiFPN_Concat2, [1]] # 21 concat EMA3 + EMA2 (1536 + 768 = 2304 channels)
  - [-1, 1, C3k2, [512, False]] # 22 reduce channels to 512

  - [22, 1, nn.Upsample, [None, 2, "nearest"]] # 23 upsample to match H and W with EMA1
  - [[-1, 15], 1, BiFPN_Concat2, [1]] # 24 concat with EMA1 (512 + 384 = 896 channels)
  - [-1, 1, C3k2, [256, False]] # 25 reduce channels to 256

  # Bottom-Up Pathway
  - [25, 1, DWConv, [256, 3, 2]]    # 26: Downsample
  - [[-1, 22], 1, BiFPN_Concat2, [1]]    # 27: BiFPN Concatenate (256 + 512 = 768 channels)
  - [-1, 1, C3k2, [512, True]]     # 28: C2f (reduce to 512 channels)

  - [28, 1, DWConv, [512, 3, 2]]    # 29: Downsample
  - [[-1, 19], 1, BiFPN_Concat2, [1]]    # 30: Concatenate with EMA3 (512 + 1536 = 2048 channels)
  - [-1, 1, C3k2, [1024, True]]    # 31: C2f (reduce to 1024 channels)

  # Detection
  - [[25, 28, 31], 1, RTDETRDecoder, [nc]]  # 32: Detect(P3, P4, P5)

# nc: 2 # number of classes
# scales:
#   s: [1.0, 1.0, 1536]

# backbone:
#   - [-1, 1, nn.Identity, []] # 0

#   # CNN (ConvNeXt Tiny)
#   - [0, 1, TorchVision, [768, "convnext_tiny", "DEFAULT", True, 2, True]]  # 1
#   - [-1, 1, Index, [192, 4]]  # extracts 4th output (1, 192, 80, 80) - 2
#   - [1, 1, Index, [384, 6]]  # extracts 6th output (1, 384, 40, 40) - 3
#   - [1, 1, Index, [768, 8]]  # extracts 8th output (1, 768, 20, 20) - 4
#   # - [-1, 1, SPPF, [768, 3]]  # 5: Add SPPF for ConvNeXt (768 channels, kernel size 5)

#   # Swin Transformer
#   - [0, 1, TorchVision, [768, swin_v2_t, DEFAULT, True, 4, True]] # 6 5
#   - [-1, 1, Index, [192, 4]] # 7 6
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 8 (multiscale 1) 7
#   - [6, 1, Index, [384, 6]] # 9 8
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 10 (multiscale 2) 9
#   - [6, 1, Index, [768, 9]] # 11 10
#   - [-1, 1, torchvision.ops.Permute, [[0, 3, 1, 2]]] # 12 (multiscale 3) 11
#   # - [-1, 1, SPPF, [768, 3]]  # 13: Add SPPF for Swin Transformer (768 channels, kernel size 5)

#   # Concat features along channel dimension
#   - [[2, 7], 1, Concat, [1]] # 14 concat scale 1 (192 + 192 = 384 channels) 12
#   - [-1, 1, EMA, [384]]      # 15 EMA for scale 1 13

#   - [[3, 9], 1, Concat, [1]] # 16 concat scale 2 (384 + 384 = 768 channels) 14
#   - [-1, 1, EMA, [768]]      # 17 EMA for scale 2 15

#   - [[4, 12], 1, Concat, [1]] # 18 concat scale 3 (768 + 768 = 1536 channels) 16
#   - [-1, 1, EMA, [1536]]      # 19 EMA for scale 3 17

# head:
#   # Top-Down Pathway
#   - [17, 1, nn.Upsample, [None, 2, "nearest"]] # 20 upsample EMA3 output to match H and W with EMA2 18
#   - [[-1, 15], 1, BiFPN_Concat2, [1]] # 21 concat EMA3 + EMA2 (1536 + 768 = 2304 channels) 19
#   - [-1, 1, C3k2, [512, False]] # 22 reduce channels to 512 20

#   - [20, 1, nn.Upsample, [None, 2, "nearest"]] # 23 upsample to match H and W with EMA1 21
#   - [[-1, 13], 1, BiFPN_Concat2, [1]] # 24 concat with EMA1 (512 + 384 = 896 channels) 22
#   - [-1, 1, C3k2, [256, False]] # 25 reduce channels to 256 23

#   # Bottom-Up Pathway
#   - [23, 1, DWConv, [256, 3, 2]]    # 26: Downsample 24
#   - [[-1, 20], 1, BiFPN_Concat2, [1]]    # 27: BiFPN Concatenate (256 + 512 = 768 channels) 25
#   - [-1, 1, C3k2, [512, True]]     # 28: C2f (reduce to 512 channels) 26

#   - [26, 1, DWConv, [512, 3, 2]]    # 29: Downsample 27
#   - [[-1, 17], 1, BiFPN_Concat2, [1]]    # 30: Concatenate with EMA3 (512 + 1536 = 2048 channels) 28
#   - [-1, 1, C3k2, [1024, True]]    # 31: C2f (reduce to 1024 channels) 29

#   # Detection
#   - [[23, 26, 29], 1, RTDETRDecoder, [nc]]  # 32: Detect(P3, P4, P5) 30
