nc: 1
scales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs
  # s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs
  # m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs
  # l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs
  # x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs

backbone:
  - [-1, 1, TorchVision, [512, "vgg16", "DEFAULT", True, 2, False,"features"]]
  - [0, 1, Index, [256, 6]]  # 1 extracts 7th output (1, 512, 80, 80) - 1
  - [0, 1, Index, [512, 11]] # 2 extracts 9th output (1, 512, 40, 40) - 2
  - [0, 1, Index, [512, 12]] #3 extracts 11th output (1, 512, 20, 20) - 3
  - [-1, 1, SPPF, [512, 5]]  #4 - P5/32 (B, 512, 20, 20)
  
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] #5
  - [[-1, 2], 1, Concat, [1]]                 # 6 cat backbone P4
  - [-1, 2, C3k2, [512, False]]               # 7

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] #8
  - [[-1, 1], 1, Concat, [1]]                  #9 cat backbone P3
  - [-1, 2, C3k2, [256, False]]                #10 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]                 #11
  - [[-1, 7], 1, Concat, [1]]                 #12 cat head P4
  - [-1, 2, C3k2, [512, False]]                #13 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]                 #14
  - [[-1, 4], 1, Concat, [1]]                 #15 cat head P5
  - [-1, 2, C3k2, [1024, True]]                # 16 (P5/32-large)

  - [[10, 13, 16], 1, Detect, [nc]] # 17 Detect(P3, P4, P5)
